{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "pytorch_notebooks",
   "display_name": "pytorch_notebooks"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([[1.],\n        [2.],\n        [3.],\n        [4.]])\ntensor([[0.],\n        [0.],\n        [1.],\n        [1.]])\n"
    }
   ],
   "source": [
    "x_data = Variable(torch.Tensor([[1.0], [2.0], [3.0], [4.0]]))\n",
    "y_data = Variable(torch.Tensor([[0.], [0.], [1.], [1.]]))\n",
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = F.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegressionModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss(size_average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimiser = torch.optim.SGD(logistic_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0 0.67\n1 0.67\n2 0.67\n3 0.67\n4 0.67\n5 0.67\n6 0.67\n7 0.67\n8 0.67\n9 0.67\n10 0.67\n11 0.67\n12 0.67\n13 0.67\n14 0.67\n15 0.67\n16 0.67\n17 0.67\n18 0.67\n19 0.67\n20 0.67\n21 0.67\n22 0.67\n23 0.67\n24 0.67\n25 0.67\n26 0.67\n27 0.67\n28 0.67\n29 0.67\n30 0.67\n31 0.67\n32 0.66\n33 0.66\n34 0.66\n35 0.66\n36 0.66\n37 0.66\n38 0.66\n39 0.66\n40 0.66\n41 0.66\n42 0.66\n43 0.66\n44 0.66\n45 0.66\n46 0.66\n47 0.66\n48 0.66\n49 0.66\n50 0.66\n51 0.66\n52 0.66\n53 0.66\n54 0.66\n55 0.66\n56 0.66\n57 0.66\n58 0.66\n59 0.66\n60 0.66\n61 0.66\n62 0.66\n63 0.66\n64 0.66\n65 0.66\n66 0.66\n67 0.66\n68 0.65\n69 0.65\n70 0.65\n71 0.65\n72 0.65\n73 0.65\n74 0.65\n75 0.65\n76 0.65\n77 0.65\n78 0.65\n79 0.65\n80 0.65\n81 0.65\n82 0.65\n83 0.65\n84 0.65\n85 0.65\n86 0.65\n87 0.65\n88 0.65\n89 0.65\n90 0.65\n91 0.65\n92 0.65\n93 0.65\n94 0.65\n95 0.65\n96 0.65\n97 0.65\n98 0.65\n99 0.65\n100 0.65\n101 0.65\n102 0.65\n103 0.65\n104 0.65\n105 0.64\n106 0.64\n107 0.64\n108 0.64\n109 0.64\n110 0.64\n111 0.64\n112 0.64\n113 0.64\n114 0.64\n115 0.64\n116 0.64\n117 0.64\n118 0.64\n119 0.64\n120 0.64\n121 0.64\n122 0.64\n123 0.64\n124 0.64\n125 0.64\n126 0.64\n127 0.64\n128 0.64\n129 0.64\n130 0.64\n131 0.64\n132 0.64\n133 0.64\n134 0.64\n135 0.64\n136 0.64\n137 0.64\n138 0.64\n139 0.64\n140 0.64\n141 0.64\n142 0.64\n143 0.63\n144 0.63\n145 0.63\n146 0.63\n147 0.63\n148 0.63\n149 0.63\n150 0.63\n151 0.63\n152 0.63\n153 0.63\n154 0.63\n155 0.63\n156 0.63\n157 0.63\n158 0.63\n159 0.63\n160 0.63\n161 0.63\n162 0.63\n163 0.63\n164 0.63\n165 0.63\n166 0.63\n167 0.63\n168 0.63\n169 0.63\n170 0.63\n171 0.63\n172 0.63\n173 0.63\n174 0.63\n175 0.63\n176 0.63\n177 0.63\n178 0.63\n179 0.63\n180 0.63\n181 0.62\n182 0.62\n183 0.62\n184 0.62\n185 0.62\n186 0.62\n187 0.62\n188 0.62\n189 0.62\n190 0.62\n191 0.62\n192 0.62\n193 0.62\n194 0.62\n195 0.62\n196 0.62\n197 0.62\n198 0.62\n199 0.62\n200 0.62\n201 0.62\n202 0.62\n203 0.62\n204 0.62\n205 0.62\n206 0.62\n207 0.62\n208 0.62\n209 0.62\n210 0.62\n211 0.62\n212 0.62\n213 0.62\n214 0.62\n215 0.62\n216 0.62\n217 0.62\n218 0.62\n219 0.62\n220 0.62\n221 0.61\n222 0.61\n223 0.61\n224 0.61\n225 0.61\n226 0.61\n227 0.61\n228 0.61\n229 0.61\n230 0.61\n231 0.61\n232 0.61\n233 0.61\n234 0.61\n235 0.61\n236 0.61\n237 0.61\n238 0.61\n239 0.61\n240 0.61\n241 0.61\n242 0.61\n243 0.61\n244 0.61\n245 0.61\n246 0.61\n247 0.61\n248 0.61\n249 0.61\n250 0.61\n251 0.61\n252 0.61\n253 0.61\n254 0.61\n255 0.61\n256 0.61\n257 0.61\n258 0.61\n259 0.61\n260 0.61\n261 0.61\n262 0.6\n263 0.6\n264 0.6\n265 0.6\n266 0.6\n267 0.6\n268 0.6\n269 0.6\n270 0.6\n271 0.6\n272 0.6\n273 0.6\n274 0.6\n275 0.6\n276 0.6\n277 0.6\n278 0.6\n279 0.6\n280 0.6\n281 0.6\n282 0.6\n283 0.6\n284 0.6\n285 0.6\n286 0.6\n287 0.6\n288 0.6\n289 0.6\n290 0.6\n291 0.6\n292 0.6\n293 0.6\n294 0.6\n295 0.6\n296 0.6\n297 0.6\n298 0.6\n299 0.6\n300 0.6\n301 0.6\n302 0.6\n303 0.6\n304 0.6\n305 0.59\n306 0.59\n307 0.59\n308 0.59\n309 0.59\n310 0.59\n311 0.59\n312 0.59\n313 0.59\n314 0.59\n315 0.59\n316 0.59\n317 0.59\n318 0.59\n319 0.59\n320 0.59\n321 0.59\n322 0.59\n323 0.59\n324 0.59\n325 0.59\n326 0.59\n327 0.59\n328 0.59\n329 0.59\n330 0.59\n331 0.59\n332 0.59\n333 0.59\n334 0.59\n335 0.59\n336 0.59\n337 0.59\n338 0.59\n339 0.59\n340 0.59\n341 0.59\n342 0.59\n343 0.59\n344 0.59\n345 0.59\n346 0.59\n347 0.59\n348 0.58\n349 0.58\n350 0.58\n351 0.58\n352 0.58\n353 0.58\n354 0.58\n355 0.58\n356 0.58\n357 0.58\n358 0.58\n359 0.58\n360 0.58\n361 0.58\n362 0.58\n363 0.58\n364 0.58\n365 0.58\n366 0.58\n367 0.58\n368 0.58\n369 0.58\n370 0.58\n371 0.58\n372 0.58\n373 0.58\n374 0.58\n375 0.58\n376 0.58\n377 0.58\n378 0.58\n379 0.58\n380 0.58\n381 0.58\n382 0.58\n383 0.58\n384 0.58\n385 0.58\n386 0.58\n387 0.58\n388 0.58\n389 0.58\n390 0.58\n391 0.58\n392 0.58\n393 0.57\n394 0.57\n395 0.57\n396 0.57\n397 0.57\n398 0.57\n399 0.57\n400 0.57\n401 0.57\n402 0.57\n403 0.57\n404 0.57\n405 0.57\n406 0.57\n407 0.57\n408 0.57\n409 0.57\n410 0.57\n411 0.57\n412 0.57\n413 0.57\n414 0.57\n415 0.57\n416 0.57\n417 0.57\n418 0.57\n419 0.57\n420 0.57\n421 0.57\n422 0.57\n423 0.57\n424 0.57\n425 0.57\n426 0.57\n427 0.57\n428 0.57\n429 0.57\n430 0.57\n431 0.57\n432 0.57\n433 0.57\n434 0.57\n435 0.57\n436 0.57\n437 0.57\n438 0.57\n439 0.56\n440 0.56\n441 0.56\n442 0.56\n443 0.56\n444 0.56\n445 0.56\n446 0.56\n447 0.56\n448 0.56\n449 0.56\n450 0.56\n451 0.56\n452 0.56\n453 0.56\n454 0.56\n455 0.56\n456 0.56\n457 0.56\n458 0.56\n459 0.56\n460 0.56\n461 0.56\n462 0.56\n463 0.56\n464 0.56\n465 0.56\n466 0.56\n467 0.56\n468 0.56\n469 0.56\n470 0.56\n471 0.56\n472 0.56\n473 0.56\n474 0.56\n475 0.56\n476 0.56\n477 0.56\n478 0.56\n479 0.56\n480 0.56\n481 0.56\n482 0.56\n483 0.56\n484 0.56\n485 0.56\n486 0.56\n487 0.55\n488 0.55\n489 0.55\n490 0.55\n491 0.55\n492 0.55\n493 0.55\n494 0.55\n495 0.55\n496 0.55\n497 0.55\n498 0.55\n499 0.55\n"
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    y_pred = logistic_model.forward(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(epoch, round(loss.data.item(), 2))\n",
    "    optimiser.zero_grad()\n",
    "    loss.backward()\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1 = Variable(torch.Tensor([[1.0]]))\n",
    "test_data_2 = Variable(torch.Tensor([[7.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([[1.]]) 0.49 False\ntensor([[7.]]) 0.92 True\n"
    }
   ],
   "source": [
    "for test_data in (test_data_1, test_data_2):\n",
    "    prediction = round(logistic_model.forward(test_data).data.item(), 2)\n",
    "    prediction_class = prediction > 0.5\n",
    "    print(test_data, prediction, prediction_class)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ]
}