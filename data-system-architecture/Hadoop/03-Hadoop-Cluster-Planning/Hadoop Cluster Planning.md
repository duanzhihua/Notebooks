# Hadoop Cluster Planning

## Principal points to consider in choosing the hardware and operating systems to host an Apache Hadoop cluster.
## Analyze the choices in selecting an OS
## Understand kernel tuning and disk swapping
## Given a scenario and workload pattern, identify a hardware configuration appropriate to the scenario
## Given a scenario, determine the ecosystem components your cluster needs to run in order to fulfill the SLA
## Cluster sizing: given a scenario and frequency of execution, identify the specifics for the workload, including CPU, memory, storage, disk I/O
## Disk Sizing and Configuration, including JBOD versus RAID, SANs, virtualization, and disk sizing requirements in a cluster
##Â Network Topologies: understand network usage in Hadoop (for both HDFS and MapReduce) and propose or identify key network design components for a given scenario
